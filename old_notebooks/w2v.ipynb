{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b782c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 17:10:53.290853: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-22 17:10:53.722323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-22 17:10:55.364488: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/tguyot/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/tguyot/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unidecode\n",
    "import re\n",
    "from spacy.cli import download\n",
    "import spacy\n",
    "import nltk\n",
    "import contractions\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a058b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go point crazy available boris n great world l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok war joke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry wily come win cup final st may text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>dun say early c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ah I think go live around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>1</td>\n",
       "      <td>nd time try contact win pound prize claim easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>0</td>\n",
       "      <td>I b go esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>0</td>\n",
       "      <td>pity mood suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>0</td>\n",
       "      <td>guy itching I act like I interested buy someth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>0</td>\n",
       "      <td>roll true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5553 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      is_spam                                                sms\n",
       "0           0  go point crazy available boris n great world l...\n",
       "1           0                                        ok war joke\n",
       "2           1  free entry wily come win cup final st may text...\n",
       "3           0                        dun say early c already say\n",
       "4           0                   ah I think go live around though\n",
       "...       ...                                                ...\n",
       "5548        1  nd time try contact win pound prize claim easy...\n",
       "5549        0                           I b go esplanade fr home\n",
       "5550        0                               pity mood suggestion\n",
       "5551        0  guy itching I act like I interested buy someth...\n",
       "5552        0                                     roll true name\n",
       "\n",
       "[5553 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import cleaned preprocess csv\n",
    "df = pd.read_csv('dataset/cleaned/cleaned_spam.csv').drop(columns=['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed70e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'boris',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_corpus(df):\n",
    "    return ' '.join(' '.join(df.sms.tolist()).split())\n",
    "\n",
    "def get_unique_words(df):\n",
    "    corpus = get_corpus(df)\n",
    "    unique = set()\n",
    "    output = []\n",
    "    for word in corpus.split():\n",
    "        if word not in unique:\n",
    "            unique.add(word)\n",
    "            output.append(word)\n",
    "    return output\n",
    "\n",
    "def count_unique(df):\n",
    "    return len(get_unique_words(df))\n",
    "\n",
    "\n",
    "\n",
    "print(count_unique(df))\n",
    "\n",
    "get_unique_words(df)[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "294dbd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOrd2Vec Model\n",
    "class NaiveWord2Vec(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.weight1 = tf.keras.layers.Dense(embedding_dim, input_shape=(vocab_size,), activation='linear', name='embedding_layer')\n",
    "        self.weight2 = tf.keras.layers.Dense(vocab_size, input_shape=(embedding_dim,), activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.weight1(inputs)\n",
    "        x = self.weight2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6526975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('txt', 0.9992980360984802),\n",
       " ('free', 0.9992956519126892),\n",
       " ('give', 0.9992565512657166),\n",
       " ('call', 0.999247133731842),\n",
       " ('make', 0.9992321729660034),\n",
       " ('phone', 0.9992314577102661),\n",
       " ('go', 0.9992285370826721),\n",
       " ('win', 0.9992283582687378),\n",
       " ('reply', 0.9992155432701111),\n",
       " ('number', 0.9991986751556396),\n",
       " ('get', 0.9991981983184814),\n",
       " ('week', 0.9991962313652039),\n",
       " ('day', 0.9991894364356995),\n",
       " ('god', 0.9991675019264221),\n",
       " ('n', 0.9991648197174072),\n",
       " ('place', 0.9991633892059326),\n",
       " ('b', 0.9991531372070312),\n",
       " ('text', 0.999146580696106),\n",
       " ('late', 0.999137282371521),\n",
       " ('take', 0.9991199970245361)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with gensim first\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms'].apply(lambda x: x.split()),\n",
    "                                                    df['is_spam'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                   vector_size=100,\n",
    "                                   window=2,\n",
    "                                   min_count=1)\n",
    "\n",
    "# Test word vectors -> lots of 0.999 cosine similarities\n",
    "w2v_model.wv.most_similar('mobile', topn=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c53052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous bag of words\n",
    "\n",
    "def generate_cbows(text, window_size):\n",
    "    \"\"\"Generate Continuous Bag of Words (CBOW) pairs from the given text. \n",
    "    text: preprocessed sequence of text\"\"\"\n",
    "    # Tokenize the text\n",
    "    words = text.split()\n",
    "\n",
    "    # Create CBOW pairs with a given window size\n",
    "    cbows = []\n",
    "    for i, target_word in enumerate(words):\n",
    "        context_words = words[max(0, i - window_size):i] + words[i + 1:i + window_size + 1]\n",
    "        if len(context_words) == window_size * 2:\n",
    "            cbows.append((context_words, target_word))\n",
    "    return cbows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c23a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word: str, unique_words: list):\n",
    "    try:\n",
    "        assert word in set(unique_words)\n",
    "    except AssertionError:\n",
    "        print(f\"Word '{word}' not found in unique_words.\")\n",
    "        return None\n",
    "    vector = np.zeros(len(unique_words))\n",
    "    index = unique_words.index(word)\n",
    "    vector[index] = 1\n",
    "    return tf.convert_to_tensor(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab02c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cbow(df, window_size):\n",
    "    # Create Cbows non-encoded\n",
    "    cbows = generate_cbows(get_corpus(df), window_size=window_size)\n",
    "\n",
    "    # One-hot-encode words\n",
    "    unique_words = list(get_unique_words(df))\n",
    "    one_hot_encodings = {\n",
    "        word: one_hot_encoding(word, unique_words) for word in unique_words\n",
    "    }\n",
    "\n",
    "    # Convert CBOW pairs to vector pairs\n",
    "    cbow_vector_pairs = [([one_hot_encodings[word] for word in context_words], one_hot_encodings[target_word]) for context_words, target_word in cbows]\n",
    "\n",
    "    # Sum the context vectors to get a single context vector\n",
    "    cbow_vector_pairs = [(tf.reduce_sum(tf.stack(context_vectors), axis=0), target_vector) for context_vectors, target_vector in cbow_vector_pairs]\n",
    "\n",
    "    return cbow_vector_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f5936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tguyot/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1769098335.093512  224202 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1180/1180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.0713 - loss: 7.1225 - val_accuracy: 0.0822 - val_loss: 6.8492\n",
      "Epoch 2/15\n",
      "\u001b[1m1180/1180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.1044 - loss: 6.2098 - val_accuracy: 0.1151 - val_loss: 6.5334\n",
      "Epoch 3/15\n",
      "\u001b[1m 725/1180\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.1566 - loss: 5.4033"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Get cbow pairs\u001b[39;00m\n\u001b[32m     16\u001b[39m cbow_vector_pairs = prepare_cbow(df, window_size=WINDOW_SIZE)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcbow_vector_pairs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcbow_vector_pairs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PersonalCode/spam-classifier/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "unique_words = list(get_unique_words(df))\n",
    "VOCAB_SIZE = len(unique_words)\n",
    "VECTOR_DIM = 250\n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "model = NaiveWord2Vec(VOCAB_SIZE, VECTOR_DIM)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Get cbow pairs\n",
    "cbow_vector_pairs = prepare_cbow(df, window_size=WINDOW_SIZE)\n",
    "\n",
    "model.fit(\n",
    "    x=tf.stack([pair[0] for pair in cbow_vector_pairs]),\n",
    "    y=tf.stack([pair[1] for pair in cbow_vector_pairs]),\n",
    "    epochs=15,\n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfae12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word embeddings\n",
    "embeddings = model.get_layer('embedding_layer').get_weights()[0]\n",
    "word_embeddings = {word: embeddings[idx] for idx, word in enumerate(unique_words)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87333f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# Get ntop similar words\n",
    "def get_top_n_similar_words(target_word, word_embeddings, n=10):\n",
    "    target_vector = word_embeddings[target_word]\n",
    "    similarities = {}\n",
    "    for word, vector in word_embeddings.items():\n",
    "        if word != target_word:\n",
    "            similarities[word] = cosine_similarity(target_vector, vector)\n",
    "    # Sort by similarity\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    return sorted_similarities[:n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240e278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bonus', np.float32(0.54364353)),\n",
       " ('ppmpoboxbhambxe', np.float32(0.51361966)),\n",
       " ('hotmix', np.float32(0.44465983)),\n",
       " ('calloptoutj', np.float32(0.414103)),\n",
       " ('todayfrom', np.float32(0.4139428)),\n",
       " ('apsaward', np.float32(0.4122826)),\n",
       " ('tushin', np.float32(0.40710118)),\n",
       " ('freefone', np.float32(0.40527236)),\n",
       " ('polyphonic', np.float32(0.40508807)),\n",
       " ('dough', np.float32(0.39912173))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_similar_words('reward', word_embeddings, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('magazine', np.float32(0.42165235)),\n",
       " ('mssuman', np.float32(0.39212197)),\n",
       " ('falconerf', np.float32(0.39149868)),\n",
       " ('priest', np.float32(0.36515862)),\n",
       " ('thuglyfe', np.float32(0.36444417)),\n",
       " ('careabout', np.float32(0.35936666)),\n",
       " ('mobstorequizppm', np.float32(0.35568982)),\n",
       " ('grahmbell', np.float32(0.352596)),\n",
       " ('parish', np.float32(0.35140562)),\n",
       " ('nitric', np.float32(0.3357464))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_similar_words('prize', word_embeddings, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e0340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-0.054397956)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(word_embeddings['phone'], word_embeddings['call']) # did not work as well as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fde5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.07887484)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(word_embeddings['text'], word_embeddings['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecea0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('limited', np.float32(0.40236196)),\n",
       " ('landlineonly', np.float32(0.3769837)),\n",
       " ('backdoor', np.float32(0.37456143)),\n",
       " ('yard', np.float32(0.35390836)),\n",
       " ('textpod', np.float32(0.3136002)),\n",
       " ('mood', np.float32(0.31198224)),\n",
       " ('broad', np.float32(0.30957416)),\n",
       " ('sac', np.float32(0.30698884)),\n",
       " ('subscription', np.float32(0.30430934)),\n",
       " ('flag', np.float32(0.3036724)),\n",
       " ('george', np.float32(0.30110094)),\n",
       " ('q', np.float32(0.29500404)),\n",
       " ('rival', np.float32(0.29429808)),\n",
       " ('optoutdwv', np.float32(0.2913026)),\n",
       " ('calloptoutndx', np.float32(0.28420985)),\n",
       " ('teacoffee', np.float32(0.28236598)),\n",
       " ('esaplanade', np.float32(0.28191766)),\n",
       " ('logic', np.float32(0.2723593)),\n",
       " ('triple', np.float32(0.27178597)),\n",
       " ('nytecalpmsgp', np.float32(0.26528463))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get ntop similar words\n",
    "def get_top_n_similar_words(target_word, word_embeddings, n=10):\n",
    "    target_vector = word_embeddings[target_word]\n",
    "    similarities = {}\n",
    "    for word, vector in word_embeddings.items():\n",
    "        if word != target_word:\n",
    "            similarities[word] = cosine_similarity(target_vector, vector)\n",
    "    # Sort by similarity\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    return sorted_similarities[:n]\n",
    "\n",
    "get_top_n_similar_words('free', word_embeddings, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01700f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bonus', np.float32(0.54364353)),\n",
       " ('ppmpoboxbhambxe', np.float32(0.51361966)),\n",
       " ('hotmix', np.float32(0.44465983)),\n",
       " ('calloptoutj', np.float32(0.414103)),\n",
       " ('todayfrom', np.float32(0.4139428)),\n",
       " ('apsaward', np.float32(0.4122826)),\n",
       " ('tushin', np.float32(0.40710118)),\n",
       " ('freefone', np.float32(0.40527236)),\n",
       " ('polyphonic', np.float32(0.40508807)),\n",
       " ('dough', np.float32(0.39912173)),\n",
       " ('quizclub', np.float32(0.39581454)),\n",
       " ('bannfwflyppm', np.float32(0.3954876)),\n",
       " ('neo', np.float32(0.3933182)),\n",
       " ('triple', np.float32(0.3862275)),\n",
       " ('vasa', np.float32(0.38414797)),\n",
       " ('subscriptngbpwk', np.float32(0.3800444)),\n",
       " ('identify', np.float32(0.3778111)),\n",
       " ('oral', np.float32(0.3687912)),\n",
       " ('videophone', np.float32(0.36657158)),\n",
       " ('smartcall', np.float32(0.35913646))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_similar_words('reward', word_embeddings, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08297729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('upgrade', np.float32(0.33815807)),\n",
       " ('rental', np.float32(0.31226462)),\n",
       " ('mrs', np.float32(0.30610892)),\n",
       " ('accessible', np.float32(0.2999165)),\n",
       " ('clip', np.float32(0.2913238)),\n",
       " ('getting', np.float32(0.28507674)),\n",
       " ('stanwood', np.float32(0.2780832)),\n",
       " ('worldgnun', np.float32(0.2761979)),\n",
       " ('nationwide', np.float32(0.26948124)),\n",
       " ('limbo', np.float32(0.2682088)),\n",
       " ('digital', np.float32(0.26754203)),\n",
       " ('tense', np.float32(0.26622087)),\n",
       " ('explosive', np.float32(0.26266536)),\n",
       " ('itplspls', np.float32(0.2603224)),\n",
       " ('refundedthis', np.float32(0.2581207)),\n",
       " ('youcarlo', np.float32(0.25473404)),\n",
       " ('anybody', np.float32(0.25124446)),\n",
       " ('engine', np.float32(0.24404491)),\n",
       " ('cela', np.float32(0.24353784)),\n",
       " ('hockey', np.float32(0.24111722))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_similar_words('phone', word_embeddings, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02dc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('multimedia', np.float32(0.4226807)),\n",
       " ('alertfrom', np.float32(0.4002517)),\n",
       " ('eckankar', np.float32(0.36506042)),\n",
       " ('personally', np.float32(0.35783258)),\n",
       " ('habbahw', np.float32(0.3513697)),\n",
       " ('messenger', np.float32(0.34484679)),\n",
       " ('multiply', np.float32(0.3417072)),\n",
       " ('recdthirtyeight', np.float32(0.3353375)),\n",
       " ('zindgi', np.float32(0.3325146)),\n",
       " ('storm', np.float32(0.31303832)),\n",
       " ('executive', np.float32(0.313)),\n",
       " ('responcewhat', np.float32(0.30844173)),\n",
       " ('intrude', np.float32(0.30188596)),\n",
       " ('noncomittal', np.float32(0.2933287)),\n",
       " ('dayswill', np.float32(0.28464863)),\n",
       " ('punch', np.float32(0.28203005)),\n",
       " ('logic', np.float32(0.28048545)),\n",
       " ('specify', np.float32(0.27729613)),\n",
       " ('border', np.float32(0.27591735)),\n",
       " ('anybody', np.float32(0.2737102))]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_similar_words('crazy', word_embeddings, n=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
